{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dfba78f-9a7c-4159-a790-52ae571c3b48",
   "metadata": {},
   "source": [
    "Q1.)  ans\n",
    "\n",
    "Overfittiing in ML Refers to Codition Where the Train Acciracy is Highr and the test accuracy is lower then the the train accuracy. Model is Trained With higher accuracy but at the time of Test if did't performed well. In Overfitting there is low bias and the variance is high.\n",
    "\n",
    "Underfitting is ML Refers to Condition where thr train accuracy is lower and the test accouracy is also lower then train accuracy, means that the model is tested with low accracy and the time of test it also showed low accuracy, in underfittig it's high bias and high variance.\n",
    "\n",
    "To counter it we must follow the Genarated model where the test and train accuracy must be in good number and the variance and bias is low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfe2f75-692e-4102-956e-9c2e3817d849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57aedb6b-1e97-4299-a40e-35c41c839ab7",
   "metadata": {},
   "source": [
    "Q2.) Ans\n",
    "\n",
    "By converting it to Generated model, we will increases the traning data and use feature selection, Cross-validation techniques "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354ba2de-4b5b-4aea-b751-2a8e0f736be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c81e228-f46a-4681-9c02-b3ecade7047c",
   "metadata": {},
   "source": [
    "Q3.) ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23de9ed-a93e-4399-a2e6-2d3c45d629f0",
   "metadata": {},
   "source": [
    "Underfitting in Ml is the Condition where Both the Train accuracy and Test accuracy is low, Because of the Low availiability of the tarning data, the model show low performance on both the train and test data, \n",
    "Scenarios where underfitting can occur in ML are.\n",
    "\n",
    "Insufficient training time If the model is not trained for enough iterations , it may not have had the opportunity to learn the underlying patterns in the data\n",
    "\n",
    "Insufficient training data When the available training data is limited or unrepresentative of the true data distribution, in that case the model may not learn the underlying patterns effectively and preciesly.\n",
    "\n",
    "Presence of Outliers If the dataset contains significant amounts of noise or outliers, the model may try to fit these instances, resulting in poor generalization and underfitting on the patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a490ac7-c5bd-4417-9906-c13f6ac271bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38d54df8-3233-4489-823f-c21787088f8d",
   "metadata": {},
   "source": [
    "Q4.) Ans\n",
    "\n",
    "The bias-variance tradeoff is a fundamental concept in machine learning that involves finding the right balance between model bias and variance to achieve optimal performance.\n",
    "\n",
    "the Bias here is the accuracy level and the variance is the variability of the model's predictions for different training datasets. A high bias model tends to oversimplify the underlying patterns in the data and may underfit, meaning it has high error both on the training data and unseen data. \n",
    "\n",
    "A high variance model is sensitive to fluctuations in the training data and may overfit, meaning it performs well on the training data but poorly on unseen data. A low variance model is more stable and generalizes well to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ec64ff-ba83-406f-b631-33a657b215e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f1948f8-9c70-4053-bb3b-45082bd2aed3",
   "metadata": {},
   "source": [
    "Q5.)  Ans\n",
    "\n",
    "Hold-Out Validation Splitting the available data into three sets: training set, validation set, and test set. The model is trained on the training set, and its performance is evaluated on both the validation set (used for hyperparameter tuning) and the test set (used for final evaluation). If the model performs significantly better on the training set than the validation or test set, it indicates overfitting.\n",
    "\n",
    "Out-of-sample Evaluation This involves evaluating the model's performance on completely unseen data, which was not used during training or validation. If the model's performance significantly deteriorates on the out-of-sample data compared to the training or validation data, it is an indication of overfitting.\n",
    "\n",
    "Residual Analysis In regression problems, analyzing the residuals (the differences between predicted and actual values) can provide insights into overfitting or underfitting. Large and systematic patterns in the residuals may indicate underfitting, while irregular and random patterns may suggest overfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b05b00-a4ed-40fc-a2ce-903232c82739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c541d7f0-c345-4a2f-9fad-831e9ad9616c",
   "metadata": {},
   "source": [
    "Q6.) Ans\n",
    "\n",
    "Bias refers to the error introduced by approximating a complex real-world problem with a simplified model. Bias measures how well the model captures the true relationship between the features and the target variable. Variance measures how much the model's predictions vary with changes in the training data. Variance refers to the variability of the model's predictions for different training datasets High variance models are highly flexible and can capture complex patterns in the data.\n",
    "\n",
    "Example of High bias\n",
    "Linear regression with only one or two features to predict a complex non-linear relationship.\n",
    "Example of High Varaiance\n",
    "A decision tree with a very large depth, capable of fitting every data point precisely.\n",
    "\n",
    "High bias models tend to have low training and test performance due to oversimplification. High variance models tend to have high training performance but significantly worse test performance due to overfitting. High bias models have a systematic error and lack the capacity to learn complex patterns. High variance models have a random error and capture noise or in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0946d47f-a0b5-49fb-8dfb-0a1f919f7798",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d911696a-c12d-4201-8a3e-ed1ded8009a4",
   "metadata": {},
   "source": [
    "Q7.) Ans\n",
    "\n",
    "Regularization in machine learning is a technique used to prevent overfitting by adding a penalty term to the model's objective function. It helps control the complexity of the model and discourages overly complex or large parameter values, promoting simpler and more generalizable models.\n",
    "\n",
    "Regularization like L1 and L2, \n",
    "L1 regularization adds the sum of the absolute values of the model's coefficients to the objective function. It encourages sparsity in the model by shrinking less important features' coefficients to zero\n",
    "L2 regularization adds the sum of the squared values of the model's coefficients to the objective function.\n",
    "It encourages small but non-zero values for all coefficients, reducing their magnitude.\n",
    "\n",
    "Regularization techniques can be used individually or combined to control the model's complexity and prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34eabc14-2de3-4684-bad0-8e4610725c42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
